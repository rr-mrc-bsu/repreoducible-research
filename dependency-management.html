<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>6 Dependency management | A Reproducible Research Compendium</title>
  <meta name="description" content="This compendium is intended is intended to be a growing knowledge base on reproducible research and by writing it collaboratively acts as learning-by-doing example on modern collaborative coding workflows and version control.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="6 Dependency management | A Reproducible Research Compendium" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This compendium is intended is intended to be a growing knowledge base on reproducible research and by writing it collaboratively acts as learning-by-doing example on modern collaborative coding workflows and version control." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6 Dependency management | A Reproducible Research Compendium" />
  
  <meta name="twitter:description" content="This compendium is intended is intended to be a growing knowledge base on reproducible research and by writing it collaboratively acts as learning-by-doing example on modern collaborative coding workflows and version control." />
  

<meta name="author" content="cf. list of contributors at https://github.com/rr-mrc-bsu/reproducible-research/graphs/contributors">


<meta name="date" content="2019-04-13">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="chptr-workflow-automation.html">
<link rel="next" href="chptr-continuous-integration.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Reproducible Research Compendium</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> A ‘Living Book’ - aims and scope</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#other-resources"><i class="fa fa-check"></i><b>1.1</b> Other resources</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#our-definition-of-reproducible-research"><i class="fa fa-check"></i><b>1.2</b> Our definition of ‘Reproducible Research’</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chptr-how-to-contribute.html"><a href="chptr-how-to-contribute.html"><i class="fa fa-check"></i><b>2</b> How to contribute</a><ul>
<li class="chapter" data-level="2.1" data-path="chptr-how-to-contribute.html"><a href="chptr-how-to-contribute.html#before-you-start"><i class="fa fa-check"></i><b>2.1</b> Before you start</a></li>
<li class="chapter" data-level="2.2" data-path="chptr-how-to-contribute.html"><a href="chptr-how-to-contribute.html#cloning-getting-the-books-source-code"><i class="fa fa-check"></i><b>2.2</b> Cloning: Getting the book’s source code</a></li>
<li class="chapter" data-level="2.3" data-path="chptr-how-to-contribute.html"><a href="chptr-how-to-contribute.html#creating-a-new-branch"><i class="fa fa-check"></i><b>2.3</b> Creating a new ‘branch’</a></li>
<li class="chapter" data-level="2.4" data-path="chptr-how-to-contribute.html"><a href="chptr-how-to-contribute.html#creating-a-new-chapter"><i class="fa fa-check"></i><b>2.4</b> Creating a new chapter</a></li>
<li class="chapter" data-level="2.5" data-path="chptr-how-to-contribute.html"><a href="chptr-how-to-contribute.html#committing-your-changes"><i class="fa fa-check"></i><b>2.5</b> Committing your changes</a></li>
<li class="chapter" data-level="2.6" data-path="chptr-how-to-contribute.html"><a href="chptr-how-to-contribute.html#publishing-your-changes"><i class="fa fa-check"></i><b>2.6</b> Publishing your changes</a></li>
<li class="chapter" data-level="2.7" data-path="chptr-how-to-contribute.html"><a href="chptr-how-to-contribute.html#easy-alternative"><i class="fa fa-check"></i><b>2.7</b> Easy alternative</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chptr-version-control.html"><a href="chptr-version-control.html"><i class="fa fa-check"></i><b>3</b> Version control</a></li>
<li class="chapter" data-level="4" data-path="chptr-literate-programming.html"><a href="chptr-literate-programming.html"><i class="fa fa-check"></i><b>4</b> Literate Programming</a></li>
<li class="chapter" data-level="5" data-path="chptr-workflow-automation.html"><a href="chptr-workflow-automation.html"><i class="fa fa-check"></i><b>5</b> Build automation</a><ul>
<li class="chapter" data-level="5.1" data-path="chptr-workflow-automation.html"><a href="chptr-workflow-automation.html#makefiles"><i class="fa fa-check"></i><b>5.1</b> Makefiles</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="dependency-management.html"><a href="dependency-management.html"><i class="fa fa-check"></i><b>6</b> Dependency management</a><ul>
<li class="chapter" data-level="6.1" data-path="dependency-management.html"><a href="dependency-management.html#example-problem"><i class="fa fa-check"></i><b>6.1</b> Example problem</a></li>
<li class="chapter" data-level="6.2" data-path="dependency-management.html"><a href="dependency-management.html#virtual-machines-and-containers"><i class="fa fa-check"></i><b>6.2</b> Virtual machines and containers</a><ul>
<li class="chapter" data-level="6.2.1" data-path="dependency-management.html"><a href="dependency-management.html#sct-docker"><i class="fa fa-check"></i><b>6.2.1</b> Docker</a></li>
<li class="chapter" data-level="6.2.2" data-path="dependency-management.html"><a href="dependency-management.html#singularity"><i class="fa fa-check"></i><b>6.2.2</b> Singularity</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="dependency-management.html"><a href="dependency-management.html#the-dockerfile"><i class="fa fa-check"></i><b>6.3</b> The dockerfile</a></li>
<li class="chapter" data-level="6.4" data-path="dependency-management.html"><a href="dependency-management.html#sct-container-workflow-manager"><i class="fa fa-check"></i><b>6.4</b> Containers and workflow management</a><ul>
<li class="chapter" data-level="6.4.1" data-path="dependency-management.html"><a href="dependency-management.html#gnu-make"><i class="fa fa-check"></i><b>6.4.1</b> GNU make</a></li>
<li class="chapter" data-level="6.4.2" data-path="dependency-management.html"><a href="dependency-management.html#snakemake"><i class="fa fa-check"></i><b>6.4.2</b> Snakemake</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="dependency-management.html"><a href="dependency-management.html#containerization-vs.package-managers"><i class="fa fa-check"></i><b>6.5</b> Containerization vs. package managers</a><ul>
<li class="chapter" data-level="6.5.1" data-path="dependency-management.html"><a href="dependency-management.html#r-only---wrap-everything-up-in-a-package"><i class="fa fa-check"></i><b>6.5.1</b> R only - wrap everything up in a package</a></li>
<li class="chapter" data-level="6.5.2" data-path="dependency-management.html"><a href="dependency-management.html#r-only---packrat"><i class="fa fa-check"></i><b>6.5.2</b> R only - packrat</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="dependency-management.html"><a href="dependency-management.html#caveats"><i class="fa fa-check"></i><b>6.6</b> Caveats</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chptr-continuous-integration.html"><a href="chptr-continuous-integration.html"><i class="fa fa-check"></i><b>7</b> Continuous Integration</a></li>
<li class="chapter" data-level="8" data-path="chptr-metadata.html"><a href="chptr-metadata.html"><i class="fa fa-check"></i><b>8</b> Metadata</a><ul>
<li class="chapter" data-level="8.1" data-path="chptr-metadata.html"><a href="chptr-metadata.html#sct-fair"><i class="fa fa-check"></i><b>8.1</b> FAIR principle</a></li>
<li class="chapter" data-level="8.2" data-path="chptr-metadata.html"><a href="chptr-metadata.html#sct-doi"><i class="fa fa-check"></i><b>8.2</b> Digital Object Identifiers - DOI</a></li>
<li class="chapter" data-level="8.3" data-path="chptr-metadata.html"><a href="chptr-metadata.html#sct-zenodo"><i class="fa fa-check"></i><b>8.3</b> Zenodo.org</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="r-package-development.html"><a href="r-package-development.html"><i class="fa fa-check"></i><b>9</b> R package development</a><ul>
<li class="chapter" data-level="9.1" data-path="r-package-development.html"><a href="r-package-development.html#continuous-integration"><i class="fa fa-check"></i><b>9.1</b> Continuous integration</a></li>
<li class="chapter" data-level="9.2" data-path="r-package-development.html"><a href="r-package-development.html#unit-testing"><i class="fa fa-check"></i><b>9.2</b> Unit testing</a></li>
<li class="chapter" data-level="9.3" data-path="r-package-development.html"><a href="r-package-development.html#documentation"><i class="fa fa-check"></i><b>9.3</b> Documentation</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="python-package-development.html"><a href="python-package-development.html"><i class="fa fa-check"></i><b>10</b> Python package development</a><ul>
<li class="chapter" data-level="10.1" data-path="python-package-development.html"><a href="python-package-development.html#continuous-integration-1"><i class="fa fa-check"></i><b>10.1</b> Continuous integration</a></li>
<li class="chapter" data-level="10.2" data-path="python-package-development.html"><a href="python-package-development.html#unit-testing-1"><i class="fa fa-check"></i><b>10.2</b> Unit testing</a></li>
<li class="chapter" data-level="10.3" data-path="python-package-development.html"><a href="python-package-development.html#documentation-1"><i class="fa fa-check"></i><b>10.3</b> Documentation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Reproducible Research Compendium</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="dependency-management" class="section level1">
<h1><span class="header-section-number">6</span> Dependency management</h1>
<p>Reproducible research, in the narrow sense in which it is defined in this book, ultimately means that an entire analysis - however complicated - can be repeated at the push of a button (or the command line equivalent: typing ‘make’) to yield the exact same figures, tables, files, or reports when aplied to the exact same data. In mathematical terms, one could go as far as requiring that an analysis must act as a function on data: there may very well be two data sets that produce the same output but the same input data must always produce the same analysis results. The core tools for achieving this are certainly literate programming, which allows to closer integrate documentation and code from a documentation-first perspective, and any form of build automation/workflow management system (GNU make, snakemake, CWL, etc.).</p>
<p>It is certainly worthwhile to take a step back here and reflect on the complexity of the approach that was put forward so far. None of the steps suggested is excessively complex or requires a particularly deep understanding of ‘the command line’ but in combination a sizeable stack of software dependencies has piled up:</p>
<ol style="list-style-type: decimal">
<li>On the base layer, there is the operating system itself.</li>
<li>The analysis is conducted by interacting with the operating system, ideally, via some form of terminal and shell.</li>
<li>Next, a workflow management system or build system like GNU make, snakemake, or CWL-runner should be used to ‘tie everything together’</li>
<li>Version control software (usually git) is required to ensure integrity of the project</li>
<li>Usually some form of output is to be produced and the most reliable way to preserve digital documents at the moment seems to be .pdf. Note that changes in html/browser support may lead to different depiction of the same html file over the years! To create this output one will typically rely on some form of literate programming which has further dependencies. In the case of Rmarkdown and pdf output that would be R + pandoc + LaTeX.</li>
<li>Finally, the analysis itself will require even more complex software (R packages, python modules). In a scientific context there might also be bleeding edge software with no stabel release at all, which needs to be build from source.</li>
</ol>
<p>All in all, this software stack is incredibly complex even for the simplest of analyses! Over time, each of these component layers might change/be updated at different pace or the developmet might simply cease. This situation can be pictured as a completed analysis being a delicate skyscraper: the moment it is finished it starts to slowly crumble away. [picture lening tower of pisa] Even if all all scripts and report files were preserved exactly in the state they were in when the analysis was conducted, the slowly evolving software ecosystem around them will still change over time and it might very well be that the excat same code would produce different results, or much more likely, simply stop working at some point.</p>
<p>It is thus not enough to simply maintain a versioned repository of all analysis scripts. Rather, complete reproducibility also requires a perfect snapshot of the software environment at the time of execution to be preserved for future execution - a time capsule of code if you will. A good first step in this direction is certainly to report as many version numbers of software used as possible. This approach, however, is cumbersome, error prone and ultimately futile since users are typically not even aware of the phletora of low level software they implicitly rely on. A better approach would be to define explicitly the computing environment required for the intended computation and to preserve an exact ‘image’ of this environemnt which can then be replicated at a later point in time to re-run the analysis in it’s original environment.</p>
<div id="example-problem" class="section level2">
<h2><span class="header-section-number">6.1</span> Example problem</h2>
<p>Consider the toy example in <a href="https://github.com/rr-mrc-bsu/containerization-example" class="uri">https://github.com/rr-mrc-bsu/containerization-example</a>. This example repository is build around a single R Markdown report (<code>r-and-python.Rmd</code>) highlighting how R and python can be integrated in a single report. While this is still a fairly simple project in terms of dependencies (no custom source dependencies) it is complex enough to highlight the benefits of a containerized analysis.</p>
<p>Let’s sort throught the individual files and folder one by one. Any well-organized repository should contain <code>README.md</code>, <code>LICENSE</code>, and <code>.gitignore</code> files. Their respective roles are described in the git chapter [write chapter, REFERENCE].</p>
<p>The <code>.travis.yml</code> configuration file contains the configuration of the continuous integration system (here: Travis-CI) linked to the repository. Continuous integration services allow automatic builds/checks of the code in a repository and greatly facilitate quality checking of new pull requests. To avoid a lengthly configuration file, the folder <code>.travis</code> contains further scripts which are referenced from the actual Travis configuration file. For details on continuous integration, see chapter <a href="chptr-continuous-integration.html#chptr-continuous-integration">7</a>.</p>
<p>The <code>Makefile</code> and the <code>Snakemake</code> files are explained in more detail in chapter ???. These files can be used to organize complex workflows using either GNU make (in simpler cases) or snakemake (more sophisticated, cluster integration). We will discuss how these two common workflow automation systems can be used together with containers at the end of this chapter in section <a href="dependency-management.html#sct-container-workflow-manager">6.4</a>.</p>
<p>The folder <code>mnist</code> contains prepared data from the classical <a href="http://yann.lecun.com/exdb/mnist/">mnist</a> digital handwritten data set.</p>
<p>The R Markdown file <code>r-and-python.Rmd</code> and the <code>docker</code> folder are the elements of the example repository most important to the contents of this chapter. The R Markdown file <code>r-and-python.Rmd</code> contains an example analysis using python and tensorflow + keras to do the heavy lifting for training a deep neural network to classify the mnist example data (in digits 0 to 9). Some data wrangling and plotting is done using R though. Both R and python sessions interoperate using the <a href="https://github.com/rstudio/reticulate"><strong>reticulate</strong> package</a>. To learn more about the language agnostic nature of R Markdown and especially python/R interoperability, see [write chapter, REFERENCE]. The analysis thus has a non-trivial set of dependencies in both R and python packages/modules, which we will manage by using a custom docker conatainer. The build instructions for this container are specified in the <code>docker</code> folder which contains a build script <code>docker/build</code> and a <code>dockerfile</code>. We will return to this folder in section <a href="dependency-management.html#sct-docker">6.2.1</a>. Before learning more about containers, it is a good idea to have a rough understanding of so called ‘virtual machines’.</p>
</div>
<div id="virtual-machines-and-containers" class="section level2">
<h2><span class="header-section-number">6.2</span> Virtual machines and containers</h2>
<p>Virtual machines are (software) emulations of entire computer systems. As such they allow running various guest operating systems from within a single host system, e.g., Linux within Windows or vice versa. To achieve this, a virtual machine acts as intermediate layer between the host system (and its hardware) and the guest operating system. i.e., all low-level operatons of the guest system are mapped through the virtual machine and the host operating system to the host hardware. A common software for running virtual machines is <a href="https://www.virtualbox.org/">VirtualBox</a> which can, e.g., be used to run an Ubuntu linux from within a Windows system. When using virtual machines for reproducible reseach, care should be taken to make the process of creating the virtual machine as transparent as possible. Command line tools like <a href="https://www.vagrantup.com/">Vagrant</a> are much better suited for theses use cases. We strongly discourage setting up a full-fledged Ubuntu system within VirtualBox and installing required software manually from within the virtual machine since this process is itself not reproducible. A virtual machine created in this way may render a particular piece of code reproducible but can itself not easily be recreated to the exact same specifications.</p>
<p>Instead, the reproducible research community is mainly embracing containers to create portable computing environments. For our purposes, containers can bee seen as a more lightweight alternative to virtual machines. Snakemake [write chapter, REFERENCE], for instance, supports running workflows where individual steps are executed in their respective individual containers.</p>
<blockquote>
<p>In a nutshell, we may see container images as lightweight portable pieces of software which can be used to spawn container instances thus creating a <strong>portable computing environment</strong> by simply distributing the respective container image file.</p>
</blockquote>
<p>If all dependencies of a particular analysis or an individual step in a larger workflow are contained in a container image, these dependencies will be available in any instance spawned from the image. An excellent video explaining the concept of a container in more detail is:</p>
<ul>
<li>Ben Corrie, ‘what is a container?’: <a href="https://www.youtube.com/watch?v=EnJ7qX9fkcU" class="uri">https://www.youtube.com/watch?v=EnJ7qX9fkcU</a></li>
</ul>
<p>By far the most common container software is Docker.</p>
<div id="sct-docker" class="section level3">
<h3><span class="header-section-number">6.2.1</span> Docker</h3>
<p><a href="https://www.docker.com/">Docker</a> constitutes the de-facto standard in terms of container software and hugely contributed to popularizing the concept of containerization in recent years. As most of the tools discussed in this book, Docker was never designed with reproducibility in mind but rather to enable the fast spinning-up of lightweight application containers to handle web-services etc. (‘micro virtualization’).</p>
<p>Since it is the de-facto standard, Docker is very well documented and the docker community edition is an open source project and available free of charge. The company behind Docker also runs an online repository, <a href="https://www.docker.com/products/docker-hub">Docker Hub</a>, for docker images which can be seen as the GitHub/GitLab equivalent for docker images. Docker Hub can be used free of charge and thus enables the storage and sharing of custom container images via the world wide web.</p>
<p>A major drawback of Docker is, that it was never intended as a user-space application but mainly as a tool for server administrators. As such it requires root access to operate. While this is fine for buidling containers from so called <code>dockerfiles</code> (cf. <code>docker/dockerfile</code> in the exampel repository), the execution of an analysis should not require root access of the user. This is especially important when computations are conducted on shared resource like HPC systems where users do not have root access.</p>
</div>
<div id="singularity" class="section level3">
<h3><span class="header-section-number">6.2.2</span> Singularity</h3>
<p>Only relatively recently, the <a href="https://www.sylabs.io/">singularity</a> container software was introduced to address this issue. Singularity was created exactly with HPC sytems and reproducibility in science in mind (see <a href="https://www.youtube.com/watch?v=DA87Ba2dpNM">this</a> video]. It does not require root access to run (but to build container images!) and thus enables HPC users to locally build container images which they can then use to run analyses on a high-performance cluster. A guiding pricipal in the development of singularity was to maintain compatibility with docker containers, i.e., singularity can be used to run standard docker containers. Since singularity is still rather a niche product, community help for docker is much easier to get online, and dockerhub is arguably the safest (and cheapest) place to store and distribute container images we still propose to use Docker for building the actual container images.</p>
</div>
</div>
<div id="the-dockerfile" class="section level2">
<h2><span class="header-section-number">6.3</span> The dockerfile</h2>
<p>A <code>dockerfile</code> contains the ‘recipe’ for building a docker container image. The complete reference of the syntax of dockerfiles can be found <a href="https://docs.docker.com/engine/reference/builder/">here</a>. For our purposes, only a few commands will suffice to set up a docker container that contains all dependencies needed to render the Rmarkdown file <code>r-and-python.Rmd</code> of the example project. In fact, the entire contents of <code>docker/dockerfile</code> boil down to:</p>
<pre><code>FROM rocker/verse:latest

MAINTAINER Kevin Kunzmann kevin.kunzmann@mrc-bsu.cam.ac.uk

# update apt
RUN sudo apt-get update

# install python and required packages
RUN sudo apt-get install -y python3-pip python3-dev python3-tk
RUN sudo pip3 install -U pip
RUN sudo pip3 install numpy matplotlib tensorflow

# install required R packages
RUN R -e &quot;install.packages(&#39;reticulate&#39;)&quot;</code></pre>
<p>Only three statements are used.</p>
<ol style="list-style-type: decimal">
<li>The <code>FROM</code> statement indicates the basis of the container. This allows to build on existing containers which may then be modified or extended to save time and storage space since images are composed of individual layers. By re-using previous layers with <code>FROM</code> the respective layer must only be saved once per container repository. Here, the container is derived from the latest version of <a href="https://www.rocker-project.org/"><code>rocker/verse</code></a>, a relatively large container consisting of a stable debian linux system with R, Rstudio, the tidyverse packges, and all software required to render Rmarkdownr reports (LaTeX) pre-installed.</li>
<li>The <code>MAINTAINER</code> field simply contains an email address to complain to.</li>
<li>The <code>RUN</code> statement can be used to execute commmands inside the container during the build. Here we use it to update the distibution package manager before installing the R package <code>reticulate</code> which enables interoperability between R and python before installing python and the required modules.</li>
</ol>
<p>We will now build the container image locally. To that end, clone the example repository to your local filesystem (cf. [TODO; REFERENCE GIT]).</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">git</span> clone https://github.com/rr-mrc-bsu/containerization-example</code></pre></div>
<p>Next, <a href="https://docs.docker.com/install/">install docker</a>, <code>cd</code> to the docker subfolder of the example repository and build the container via</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="bu">cd</span> containerization-example/docker
<span class="fu">sudo</span> docker build --no-cache -t mycontainer .</code></pre></div>
<p>Note that you do require root access to build the container! This command will trigger the build process (and take a while). Afterwards, a success message is displayed together with a unique <a href="https://en.wikipedia.org/wiki/SHA-2">sha256 hash</a> value for the container image. This hash value can later be used to uniquely identify a particular version of a container (similar to git commit hashes, cf. ???). Should you have a Docker Hub account you could then push the image by</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">docker</span> push yourname/mycontainer</code></pre></div>
<p>These are essentially the steps executed in the <code>docker/build</code> script. WIthout making an image publicly available on dockerhub, the image is only available locally. Note that having access to the image (or at least its exact hash) is extremely important to guarantee reproducibility. Simply rebuilding the image from the same dockerfile at a later timepoint will almost always result in a slightly different image when the build is configured to use the most recent package sources and versions of the software required. To avoid this, one may take steps to specify the software versions explicitly in the dockerfile but this never guarantees reproducible builds due to the many uncontrollable external dependencies. Still, keeping the dockerfile is important, since it may be seen as a guide as to how a similar computing environment can be set up manually at a later timepoint. Even if there are reasons not to use singularity to re-run an analysis, as good dockerfile might be the best way to specify software dependencies.</p>
<p>[TODO link to continuous integration for dockerfiles]</p>
<p>Switch back to the top level of the containerization example folder now.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="bu">cd</span> ..</code></pre></div>
<p>A major advantage of singularity over docker over virtual machines is the ease with which singularity enables execution of commands <strong>inside of a docker container instance</strong> but <strong>within the host file system</strong>, i.e., in contrast to docker, one does not need to manually mount a particular directory when starting a container but simply may invoke</p>
<pre><code>singularity exec docker://kkmann/rr-containerization-example touch test</code></pre>
<p>to execute the command <code>touch test</code> in an instance of the publicly built container image but <strong>within the host filesystem</strong>. This means that after executing the line in a shell, a new file ‘test’ should have been created in the current working directory. The touch command, however, was not executed in the host system but within the container! This example is obviously useless since <code>touch</code> is just as well available in the host shell but it immediately demonstrates the ease of using singularity with the host file system!</p>
</div>
<div id="sct-container-workflow-manager" class="section level2">
<h2><span class="header-section-number">6.4</span> Containers and workflow management</h2>
<div id="gnu-make" class="section level3">
<h3><span class="header-section-number">6.4.1</span> GNU make</h3>
<p>A much more useful application in our context is executing GNU make in a container! This means that we can render the Rmarkdown file in our container by</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">singularity</span> exec docker://kkmann/rr-containerization-example make</code></pre></div>
<p>Since all dependencies are pre-installed in the container image, this command only depends on the verson of singularity and the exact container image. To query the exact sha256 hash value, use <code>docker images</code></p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">docker</span> images --digest <span class="kw">|</span> <span class="fu">grep</span> containerization</code></pre></div>
<p>which will list the locally available corresponding container images and there exact hash values. To re-use a particular version, one may then invoke, e.g.,</p>
<pre><code>singularity exec docker://kkmann/rr-containerization-example@sha256:5225e53f934d749bf3017f140e5169b0d2eadc0512799b89c2f854a2d002d0c4 make</code></pre>
</div>
<div id="snakemake" class="section level3">
<h3><span class="header-section-number">6.4.2</span> Snakemake</h3>
<p>Snakemake is a much more powerful tool whe it comes to complex workflows since it supports cluster execution and more flexible rule definitions (cf chapter [TODO, REFERENCE]). It is also designed with reproducibility in mind and thus allows to run either specific rules or an entire workflow using singularity. The contents of the <code>Snakefile</code> in the containerization-example folder are</p>
<pre><code>singularity:
    &quot;docker://kkmann/rr-containerization-example@sha256:17414f63929b0283f82e70ded3ca9cd9b61f37e13fe3d103a2bdf24b9056114e&quot;

rule build_report:
    input:
        &quot;r-and-python.Rmd&quot;
    output:
        &quot;r-and-python.html&quot;
    shell:
        &quot;&quot;&quot;
        Rscript -e &quot;rmarkdown::render(\\&quot;{input}\\&quot;)&quot;
        &quot;&quot;&quot;</code></pre>
<p>The first line specifies the singularity container to use. Here, the publicly available image from dockerhub is used with a particular hash value. One could just as well point to a local image as well though. Such a global singularity parameter will run every rule of the workflow in the same default container. It is also possible to specify custom containers on a per-rule basis by specifying the <code>singularity</code> parameter of the rule.</p>
<pre><code>rule build_report:
    input:
        &quot;r-and-python.Rmd&quot;
    output:
        &quot;r-and-python.html&quot;
    singularity:
        &quot;docker://kkmann/rr-containerization-example@sha256:17414f63929b0283f82e70ded3ca9cd9b61f37e13fe3d103a2bdf24b9056114e&quot;
    shell:
        &quot;&quot;&quot;
        Rscript -e &quot;rmarkdown::render(\\&quot;{input}\\&quot;)&quot;
        &quot;&quot;&quot;</code></pre>
<p>This will override potential gloabl singularity container settings (cf. [REFERENE SINGULARITY CHAPTER]).</p>
</div>
</div>
<div id="containerization-vs.package-managers" class="section level2">
<h2><span class="header-section-number">6.5</span> Containerization vs. package managers</h2>
<p>The approach to dependency management presented in this chapter might be considered a bit overpowered for some use cases. The main reason why we chose to demonstrate what we consider the ‘gold-standard’ of dependency management over more language/environment specific approaches is to is to showcase how simple it actually is. As long as you are capable of running a few simple commands in a Linux command line you are good to go. The container-based approach to dependency managemnt is also the most generic in that it is capable of managing arbitrary dependencies - as long as your computing environment can be set up on a Linux operating system you are good to go! It does not matter which (or even how many different) programming languages you use, how much messy custom research software you need. As long as you are able to install it to a plain Linux system there is no environment that cannot be mapped to a container (or several!). Still, for completeness’ sake, a few different, potentially more accessible methods for partial dependency management will be discussed as ‘honorable mentions’ in the following.</p>
<div id="r-only---wrap-everything-up-in-a-package" class="section level3">
<h3><span class="header-section-number">6.5.1</span> R only - wrap everything up in a package</h3>
<p>In case your entire workflow is R-based, it might be worthwhile to write an R packge for your analysis. This essentially relies on R’s package management system to resolve dependencies (in this case: R packages only). An R analysis package tends to not contain much code in the <code>R/</code> folder, but rather encapsulates any analyses in vignettes. [TODO: elaborate on this idea, example repository]</p>
</div>
<div id="r-only---packrat" class="section level3">
<h3><span class="header-section-number">6.5.2</span> R only - packrat</h3>
<p>[TODO]</p>
</div>
</div>
<div id="caveats" class="section level2">
<h2><span class="header-section-number">6.6</span> Caveats</h2>
<p>Depending on your perspective, there are a few restrictions to a container-based dependency management approach.</p>
<ol style="list-style-type: decimal">
<li><strong>Licensing:</strong> Reproducibility and the open-source philosophy are closely connected in that true reproducibility requires the software dependencies to be openly available. If the required dependencies cannot be installed in a container that may be distributed openly, results will not be reproducible by everybody. For instance, while the SAS system for statistical analyses can be used inside containers, licensing and license consts may be a major obstacle in doing so.</li>
<li><strong>Containers are Linux based:</strong> The effective restriction to open-source software also restricts the choice of container operating systems. In practice, containers are almost exclusively Linux based. In case of, e.g., Windows dependencies, this means that the less flexible approach via virtual machines might be required to encapsulate the analysis environment.</li>
</ol>
<p>While these restrictions might be seen as caveats, in fact, they can also be seen as an encouragement to conducting research in a more open (as in open-source-software-based) way.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chptr-workflow-automation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chptr-continuous-integration.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rr-mrc-bsu/reproducible-research/blob/master/15-containerization.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["reproducible-research.pdf", "reproducible-research.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
